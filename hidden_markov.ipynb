{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "DAUCAU = \",;-.?!:…\"\n",
    "DAUCAU_POS = \",,......\"\n",
    "DAUCAU_POS = \",;-.?!:…\"\n",
    "DAUCAU_POS = \".\" * len(DAUCAU)\n",
    "\n",
    "\n",
    "# input and out processing\n",
    "def words_to_word( words ):\n",
    "\treturn \"_\".join(words)\n",
    "def preprocess_sen(sen):\n",
    "\tsen = sen.lower()\n",
    "\tsen = sen.replace(\"%\", \"\")\n",
    "\tsen = sen.replace(\"\\n\", \"\")\n",
    "\n",
    "\t\n",
    "\tfor c in DAUCAU:\n",
    "\t\tsen = sen.replace(c, \" \"+c+\" \")\n",
    "\n",
    "\treturn sen\n",
    "def sen_to_words( sen ):\n",
    "\n",
    "\tdef fullOfSpace( str ):\n",
    "\t\tfor c in str:\n",
    "\t\t\tif c != ' ':\n",
    "\t\t\t\treturn False \n",
    "\t\t\n",
    "\t\treturn True \n",
    "\n",
    "\tsen = preprocess_sen( sen )\n",
    "\n",
    "\tsen_words = [ w for w in sen.split(\" \") if not fullOfSpace(w) ]\n",
    "\n",
    "\t\n",
    "\treturn sen_words\n",
    "def words_and_pos_to_output_sen( sen_words, sen_pos ):\n",
    "\toutput = \"\"\n",
    "\tn = len( sen_words)\n",
    "\tcomma = ','\n",
    "\tdot = '.'\n",
    "\n",
    "\t# hide pos of ',' and '.'\n",
    "\tfor i in range(n ):\n",
    "\t\tif i ==0 or sen_words[i] in (comma, dot):\n",
    "\t\t\toutput += sen_words[i]\n",
    "\t\telse:\n",
    "\t\t\toutput += ' ' + sen_words[i]\n",
    "\t\t\n",
    "\t\tif not sen_words[i] in (comma,dot):\n",
    "\t\t\toutput += \"/\" + sen_pos[i].upper()\n",
    "\n",
    "\n",
    "\n",
    "\treturn output\n",
    "def file_to_tagged_data( path ):\n",
    "\tfile = open(path, \"r\", encoding=\"utf8\")\n",
    "\ttext = file.readlines()\n",
    "\n",
    "\ttagged_data = []\n",
    "\n",
    "\tfor line in text:\n",
    "\t\ttagged_line = []\n",
    "\n",
    "\t\tline_words = sen_to_words( line )\n",
    "\n",
    "\t\tfor w in line_words:\n",
    "\t\t\tif w in DAUCAU:\n",
    "\t\t\t\tDAUCAU_index = DAUCAU.index(w)\n",
    "\t\t\t\ttagged_line.append((w,DAUCAU_POS[DAUCAU_index]))\n",
    "\t\t\telse:\n",
    "\t\t\t\ts = w.split(\"/\")\n",
    "\t\t\t\ttagged_line.append((s[0], s[1]))\n",
    "\n",
    "\t\ttagged_data.append( tagged_line )\n",
    "\n",
    "\treturn tagged_data\n",
    "\n",
    "#tach tu bang thuat toan Longest matching\n",
    "def Longest_matching( sen, words_list):\n",
    "\twords = sen_to_words(sen)\n",
    "\ttokens = []\n",
    "\tn = len( words )\n",
    "\ts = 0\n",
    "\twhile s < n :\n",
    "\t\te = n\n",
    "\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\twhile ( not word in words_list ) and e>s+1:\n",
    "\t\t\te -= 1\n",
    "\t\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\ttokens.append( word )\n",
    "\t\tif e <= s :\n",
    "\t\t\ts += 1\n",
    "\t\telse:\n",
    "\t\t\ts = e\n",
    "\n",
    "\treturn tokens\n",
    "\n",
    "#gan nhan tu loai tuyen tinh\n",
    "def find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len(words)\n",
    "\treturn_pos = []\n",
    "\treturn_pro = 1\n",
    "\tfor i in range( n ):\n",
    "\t\tw = words[i]\n",
    "\t\tif w in DAUCAU:\n",
    "\t\t\tDAUCAU_index = DAUCAU.index(w)\n",
    "\t\t\treturn_pos.append(DAUCAU_POS[DAUCAU_index])\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\t\tpro = 0\n",
    "\t\t\taccept_pos = \"\"\n",
    "\t\t\tfor pos in accept_tags_list:\n",
    "\t\t\t\ttemp_pro = 1\n",
    "\t\t\t\t#calculate prepos-pos\n",
    "\t\t\t\tx_index = tags_list.index( pos )\n",
    "\t\t\t\ty_index = 0\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\ty_index = len(tags_list)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ty_index = tags_list.index( return_pos[i-1] )\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_markov_matrix[y_index,x_index]\n",
    "\t\t\t\t#calculate pos-word\n",
    "\t\t\t\ty_index = tags_list.index( pos )\n",
    "\t\t\t\tx_index = 0\n",
    "\t\t\t\tif w in words_list:\n",
    "\t\t\t\t\tx_index = words_list.index(w)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\t\t\t\tif temp_pro > pro:\n",
    "\t\t\t\t\tpro = temp_pro\n",
    "\t\t\t\t\taccept_pos = pos\n",
    "\t\t\t\n",
    "\t\t\treturn_pos.append( accept_pos )\n",
    "\t\t\treturn_pro *= pro\n",
    "\n",
    "\treturn return_pos, return_pro\n",
    "\n",
    "#gan nhan tu loai quy hoach dong (de quy) #CANCELED\n",
    "def Probality_words_pos( sen_words, sen_pos, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tif len(sen_words) != len(sen_pos):\n",
    "\t\treturn 0\n",
    "\n",
    "\tpro = 1\n",
    "\tfor i in range( len( sen_pos)):\n",
    "\t\tx_index = tags_list.index( sen_pos[i] )\n",
    "\t\ty_index = 0\n",
    "\t\tif i == 0:\n",
    "\t\t\ty_index = len( tags_list)\n",
    "\t\telse:\n",
    "\t\t\ty_index = tags_list.index( sen_pos[i-1] )\n",
    "\n",
    "\t\tpro *= hidden_markov_matrix[y_index,x_index]\n",
    "\n",
    "\tfor word, pos in zip( sen_words, sen_pos ):\n",
    "\t\ty_index = tags_list.index(pos)\n",
    "\t\tx_index = 0\n",
    "\t\tif word in words_list:\n",
    "\t\t\tx_index = words_list.index( word )\n",
    "\t\telse:\n",
    "\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\tpro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\treturn pro\n",
    "def recur_find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len( words )\n",
    "\n",
    "\tdef recur_find_pos( pos_list,words, n, hidden_markov_matrix, hidden_to_observed_matrix):\n",
    "\t\t# stop\n",
    "\t\tif len(pos_list) == n:\n",
    "\t\t\treturn pos_list, Probality_words_pos( words, pos_list, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\t\n",
    "\t\tpro = 0\n",
    "\t\treturn_pos_list = []\n",
    "\t\tword_index = len(pos_list)\n",
    "\n",
    "\t\taccept_tags_list = []\n",
    "\t\tif words[ word_index ] not in DAUCAU:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [words[word_index]]\n",
    "\n",
    "\t\tfor pos in accept_tags_list:\n",
    "\t\t\tnew_pos_list, new_pro = recur_find_pos( pos_list[:] + [pos], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\t\t\tif new_pro > pro:\n",
    "\t\t\t\treturn_pos_list = new_pos_list\n",
    "\t\t\t\tpro = new_pro\n",
    "\t\t\n",
    "\t\treturn return_pos_list, pro\n",
    "\t\n",
    "\treturn recur_find_pos([], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\n",
    "\t\n",
    "def get_words_count_from_tagged_data(tagged_data):\n",
    "\twords = {} \n",
    "\tfor line in tagged_data:\n",
    "\t\tfor w, _ in line :\n",
    "\t\t\tif not w in words.keys():\n",
    "\t\t\t\twords[w] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[w] += 1\n",
    "\t\n",
    "\treturn words\n",
    "def get_tags_count_from_tagged_data(tagged_data):\n",
    "\twords = {} \n",
    "\tfor line in tagged_data:\n",
    "\t\tfor _, w in line :\n",
    "\t\t\tif not w in words.keys():\n",
    "\t\t\t\twords[w] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[w] += 1\n",
    "\t\n",
    "\treturn words\n",
    "def get_only_tags_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor _, tag in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_only_words_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor tag,_ in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_tags_list_from_tagged_data( tagged_data ):\n",
    "\ttags = []\n",
    "\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor _, tag in line :\n",
    "\t\t\tif not tag in tags:\n",
    "\t\t\t\ttags.append(tag)\n",
    "\t\n",
    "\treturn tags\n",
    "def get_words_list_from_tagged_data( tagged_data ):\n",
    "\twords = []\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor w, _ in line :\n",
    "\t\t\tif not w in words:\n",
    "\t\t\t\twords.append(w)\n",
    "\t\n",
    "\treturn words\n",
    "\n",
    "def Accuracy_on_test_data( test_data ):\n",
    "\ttest_pos = get_only_tags_from_tagged_data(test_data)\n",
    "\ttest_words = get_only_words_from_tagged_data( test_data )\n",
    "\n",
    "\ttotal_n_pos = 0\n",
    "\tfor sen_pos in test_pos:\n",
    "\t\ttotal_n_pos += len(sen_pos)\n",
    "\n",
    "\ttest_sens = []\n",
    "\tfor sen_words in test_words:\n",
    "\t\tsen = \" \".join(sen_words)\n",
    "\t\tsen = sen.replace(\"_\",\" \")\n",
    "\t\ttest_sens.append( sen )\n",
    "\n",
    "\n",
    "\tcorrect = 0\n",
    "\tfor i in range( len( test_sens )):\n",
    "\t\tprint(\"--------------------------------\")\n",
    "\t\ttest_sen_words = Longest_matching( test_sens[i], words_list )\n",
    "\t\tresult_pos, pro = find_pos_for_words( test_sen_words, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\tprint(words_and_pos_to_output_sen( test_sen_words, result_pos))\n",
    "\t\tfor j in range( len(test_pos[i]) ):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tif result_pos[j] == test_pos[i][j] and result_pos[j] not in DAUCAU:\n",
    "\t\t\t\t\tcorrect += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\treturn correct/ total_n_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = file_to_tagged_data( \"train_data.txt\")\n",
    "test_data = file_to_tagged_data( \"test_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gia_đình': 7, 'là': 20, 'tổ_ấm': 1, 'hạnh_phúc': 1, '.': 48, 'hôm_nay': 2, 'trời': 1, 'đẹp': 3, 'quá': 1, 'tôi': 11, 'thua_thiệt': 1, 'với': 9, 'bạn_bè': 1, 'ba': 2, 'người': 9, 'đàn_ông': 1, 'trụ_cột': 1, 'trong': 12, 'bố_mẹ': 1, 'tuyệt_vời': 1, 'nhất': 1, 'đối_với': 3, 'chúng_ta': 1, 'hoa_hồng': 1, 'một': 12, 'loài_hoa': 1, 'yêu': 1, 'quê_hương': 1, ',': 43, 'đất_nước': 2, 'tiếng_việt': 1, 'cực_kỳ': 1, 'phong_phú': 1, 'có_thể': 2, 'nói': 4, 'phức_tạp': 1, 'cấu_tạo': 1, 'và': 11, 'cả': 2, 'ngữ_nghĩa': 1, 'ai': 1, 'cũng': 3, 'có': 4, 'tổ_tiên': 4, 'cội_nguồn': 1, 'để': 7, 'nhớ': 1, 'máy_tính': 1, 'rất': 3, 'quan_trọng': 2, 'đặc_biệt': 1, 'sinh_viên': 1, 'xe_máy': 1, 'phương_tiên': 1, 'lưu_thông': 1, 'còn': 3, 'điện_thoại': 1, 'phương_tiện': 1, 'liên_lạc': 1, 'chàng_trai': 1, 'bơ_vơ': 1, 'từ': 2, 'xa': 1, 'tim': 1, 'hụt_hẫn': 1, 'như': 1, 'mất': 3, 'thứ': 1, 'gì': 1, 'chăm_chỉ': 1, 'đọc': 1, 'sách': 1, 'hoàn_thiện': 1, 'bản_thân': 2, 'học_tập': 1, 'học_hỏi': 1, 'không': 6, 'ngừng': 1, 'nâng_cao': 1, 'đường_sá': 1, 'sài_gòn': 1, 'đông_đúc': 1, 'nơi': 1, 'sinh': 1, 'ra': 2, 'lớn': 1, 'lên': 1, 'khi': 2, 'bạn': 2, 'nuôi': 1, 'con_vật': 1, 'phải': 1, 'sẵn_sàng': 1, 'chấp_nhận': 1, 'nổi_đau': 1, 'đi': 1, 'chúng': 1, 'thích': 2, 'vẽ': 1, 'chơi': 1, 'bóng_đá': 1, 'đây': 5, 'câu': 1, 'bình_thường': 1, 'những': 11, 'điều': 2, 'đơn_giản': 1, 'nhiều': 3, 'ít': 1, 'họ': 4, 'cười': 2, 'vì': 2, 'giống': 1, 'bị': 1, 'ngu': 1, 'đang': 1, 'viết': 1, 'dòng': 1, 'ngu_ngốc': 1, 'chính': 1, 'thủ_phạm': 1, 'chỉ': 3, 'ăn': 1, 'trái': 1, 'dưa_hấu': 1, 'đó': 3, 'anh_ấy': 1, 'thường_xuyên': 1, 'tắm': 1, 'lâu': 1, 'em': 1, 'cám_ơn': 1, 'ạ': 1, 'à': 1, 'thôi': 1, 'anh': 1, 'làm': 1, 'việc': 1, 'đâu': 1, 'tết_nguyên_đán': 6, 'khoảng': 4, 'thời_gian': 3, 'chuyển_giao': 1, 'giữa': 2, 'năm': 11, 'cũ': 3, 'mới': 5, 'âm_lịch': 3, 'mà': 2, 'nó': 1, 'chứa_đựng': 1, 'ý_nghĩa': 1, 'tâm_linh': 1, 'văn_hóa': 1, 'theo': 3, 'quan_niệm': 2, 'phương_đông': 1, 'trời_đất': 1, 'sự': 3, 'giao_hòa': 2, 'con_người': 2, 'trở_nên': 2, 'gần': 1, 'thần_linh': 2, 'của': 10, 'việt_nam': 3, 'được': 6, 'tính': 1, 'muộn': 1, 'hơn': 4, 'tết_dương_lịch': 1, 'do': 1, 'quy_luật': 1, 'nhuận': 1, 'tháng': 3, 'nên': 1, 'ngày': 12, 'đầu': 3, 'dịp': 5, 'không_bao_giờ': 1, 'trước': 1, 'hai_mười_mốt': 1, 'dương_lịch': 2, 'sau': 2, 'mười_chín': 1, 'hai': 1, 'thường': 3, 'rơi': 1, 'vào': 3, 'này': 1, 'diễn_ra': 1, 'hàng_năm': 1, 'kéo_dài': 1, 'bảy': 2, '-': 1, 'tám': 1, 'cuối': 1, 'nông_dân': 1, 'bày_tỏ': 1, 'lòng': 2, 'thành_kính': 1, 'đến': 2, 'các': 2, 'vị': 1, 'cầu': 1, 'cho': 4, 'mưa': 1, 'thuận': 1, 'gió': 1, 'hòa': 1, 'mùa_màng': 1, 'bội_thu': 1, 'bên_cạnh': 1, 'coi': 1, 'làm_mới': 2, 'mọi': 4, 'hy_vọng': 1, 'an_lành': 1, 'sung_túc': 1, 'thuận_lợi': 1, 'cả_năm': 1, 'gác_lại': 1, 'may_mắn': 1, 'do_vậy': 1, 'tết': 6, 'nhà': 1, 'nào': 1, 'tất_bật': 1, 'dọn_dẹp': 1, 'sắm_sửa': 1, 'trang_hoàng': 1, 'nhà_cửa': 1, 'thật': 1, 'lại': 2, 'về': 1, 'phần': 1, 'tình_cảm': 4, 'tinh_thần': 2, 'mối': 2, 'liên_hệ': 1, 'người_thân': 2, 'gắn_bó': 2, 'thoải_mái': 1, 'tươi_vui': 1, 'tụ_họp': 1, 'chúc_tết': 1, 'nhau': 1, 'cùng_nhau': 1, 'thắp': 1, 'nén_hương': 1, 'tưởng_nhớ': 2, 'ông_bà': 2, 'tạ_ơn': 1, 'đã': 3, 'phù_hộ': 1, 'suốt': 1, 'qua': 1, 'xuân': 1, 'đoàn_tụ': 1, 'đoàn_viên': 1, 'quan_hệ': 1, 'họ_hàng': 1, 'làng_xóm': 1, 'mở_rộng': 1, 'ràng_buộc': 1, 'lẫn_nhau': 1, 'thành': 1, 'đạo_lý': 1, 'chung': 1, 'xã_hội': 1, ':': 1, 'thầy_trò': 1, 'bệnh_nhân': 1, 'thầy_thuốc': 1, 'ông_mai': 1, 'bà_mối': 1, 'đã_từng': 1, 'tác_thành': 1, 'đôi_lứa': 1, 'bè_bạn': 1, 'cố_tri': 1, '…': 1, 'mỗi': 1, 'bàn_thờ': 3, 'gia_tiên': 3, 'vị_trí': 1, 'thể_hiện': 1, 'kính_trọng': 1, 'người_việt': 1, 'khuất': 1, 'mâm': 1, 'ngũ_quả': 1, 'lựa_chọn': 1, 'kỹ_lưỡng': 1, ';': 1, 'mâm_cỗ': 1, 'món': 1, 'ngon': 1, 'hay': 1, 'món_ăn': 1, 'quen_thuộc': 1, 'hết': 1, 'khói_hương': 1, 'trên': 1, 'quyện': 1, 'không_khí': 1, 'thiêng_liêng': 1, 'vũ_trụ': 1, 'làm_cho': 1, 'mình': 2, 'bao_giờ_hết': 1, 'cuộc_sống': 2, 'bắt_đầu': 1, 'chu_trình': 1, 'trở_về': 1, 'công_việc': 1, 'thường_nhật': 1, 'mang_theo': 1, 'đầm_ấm': 1, 'hướng_đến': 1, 'niềm_vui': 1, 'thành_công': 1, 'tương_lai': 1}\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "train_words_count = get_words_count_from_tagged_data(tagged_data)\n",
    "print(train_words_count)\n",
    "print( len(train_words_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 210, 'v': 105, 'a': 52, '.': 95, 'w': 18, 'p': 47, 'q': 76, 'm': 19, 't': 14, 'd': 15, 'l': 23, 'c': 4, 'i': 4}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "train_tags_count = get_tags_count_from_tagged_data(tagged_data)\n",
    "print(train_tags_count)\n",
    "print( len(train_tags_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden markov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  hidden markov matrix\n",
    "#\n",
    "#  ---------------------------\n",
    "#  \t   |tag0|tag1|...|tagN|\n",
    "#  --------+-------------------\n",
    "#  tag0    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  ...     |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  tagN    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  <s>     |    |    |   |    |\n",
    "#  ----------------------------\n",
    "\n",
    "\n",
    "#  hidden to observed matrix\n",
    "#\n",
    "#  --------------------------------------+\n",
    "#  \t   |word0|word1|...|wordM|unknown|\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tag0    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  ...     |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tagN    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words list (dictionary), tags list, tags chains\n",
    "words_list = get_words_list_from_tagged_data( tagged_data )+ [\"unknown\"]\n",
    "tags = get_only_tags_from_tagged_data( tagged_data )\n",
    "tags_list = get_tags_list_from_tagged_data(tagged_data)\n",
    "\n",
    "\n",
    "# create new matrix reference to hidden markov chain\n",
    "n = len(tags_list)\n",
    "hidden_markov_matrix = np.zeros((n+1,n))\n",
    "for line in tags:\n",
    "\ti = 0\n",
    "\tn = len( line )\n",
    "\twhile i < n:\n",
    "\t\tif i == 0:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = len(tags_list)\n",
    "\t\telse:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = tags_list.index(line[i-1])\n",
    "\n",
    "\t\thidden_markov_matrix[y_index,x_index] += 1\n",
    "\t\ti+=1 \n",
    "\n",
    "# create matrix reference to hidden-to-observed connect\n",
    "n_tags = len(tags_list)\n",
    "n_words = len(words_list)\n",
    "\n",
    "hidden_to_observed_matrix = np.zeros((n_tags,n_words+1))\n",
    "for line in tagged_data:\n",
    "\tfor w, tag in line :\n",
    "\t\ty_index = tags_list.index(tag)\n",
    "\t\tx_index = words_list.index(w)\n",
    "\n",
    "\t\thidden_to_observed_matrix[y_index,x_index] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smooth and calculate probality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth\n",
    "hidden_markov_matrix = hidden_markov_matrix + 0.1\n",
    "hidden_to_observed_matrix = hidden_to_observed_matrix + 0.1\n",
    "\n",
    "#calculate probality\n",
    "for i in range( hidden_markov_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_markov_matrix[i] )\n",
    "\thidden_markov_matrix[i] = hidden_markov_matrix[i] / total\n",
    "\n",
    "for i in range( hidden_to_observed_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_to_observed_matrix[i] )\n",
    "\thidden_to_observed_matrix[i] = hidden_to_observed_matrix[i] / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tôi', 'yêu', 'bóng_đá', 'và', 'đất_nước']\n",
      "['n', 'v', 'n', 'q', 'n']\n",
      "tôi/N yêu/V bóng_đá/N và/Q đất_nước/N\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "sen = \"Tôi yêu bóng đá và đất nước\"\n",
    "sen_words = Longest_matching( sen , words_list)\n",
    "sen_pos, probality = find_pos_for_words( sen_words, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\n",
    "print( sen_words )\n",
    "print( sen_pos )\n",
    "print(words_and_pos_to_output_sen( sen_words, sen_pos ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "hôm_nay/W gia_đình/N hạnh_phúc/A.\n",
      "--------------------------------\n",
      "anh/N chỉ/P thích/V em/N thôi/A.\n",
      "--------------------------------\n",
      "tôi/N đang/P chơi/V bóng_đá/N.\n",
      "--------------------------------\n",
      "tôi/N yêu/V hoa_hồng/N.\n",
      "--------------------------------\n",
      "tôi/N thường_xuyên/W ăn/V dưa_hấu/N.\n",
      "--------------------------------\n",
      "học_tập/V để/Q bản_thân/N không/P thua_thiệt/V với/Q bạn_bè/N.\n",
      "--------------------------------\n",
      "tôi/N ghét/A chơi/V bóng/P.\n",
      "--------------------------------\n",
      "ai/D cũng/P tắm/V.\n",
      "--------------------------------\n",
      "tết_nguyên_đán/N là/V ngày/N đoàn_tụ/V gia_đình/N.\n",
      "--------------------------------\n",
      "đây/D là/V khoảng/L thời_gian/N thiêng_liêng/A của/Q người_việt/N nam/A.\n",
      "--------------------------------\n",
      "mọi/L người/N trong/Q gia_đình/N chúc_tết/V ông_bà/N.\n",
      "--------------------------------\n",
      "ngày/N để/Q tưởng_nhớ/V những/L người_thân/N đã/P mất/V.\n",
      "--------------------------------\n",
      "thầy_thuốc/N không_bao_giờ/P lựa_chọn/V món_ăn/N ngon/A.\n",
      "--------------------------------\n",
      "trong/Q dịp/N tết_dương_lịch/N, người_việt/N sắm_sửa/V hai/M mươi/N mốt/A mâm/N ngũ_quả/N.\n",
      "--------------------------------\n",
      "gia_đình/N rất/P quan_trọng/A đối_với/Q mỗi/L con_người/N.\n",
      "--------------------------------\n",
      "ngày/N gia_đình/N dọn_dẹp/V là/V ngày/N mười_chín/M tháng/N một/M hàng_năm/N.\n",
      "--------------------------------\n",
      "nén_hương/N bắt_đầu/V quyện/V vào/Q không_khí/N thiêng_liêng/A ngày/N tết/N.\n",
      "--------------------------------\n",
      "tết_nguyên_đán/N là/V dịp/N ý_nghĩa/N để/Q tưởng_nhớ/V tổ_tiên/N.\n",
      "--------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7768595041322314"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_on_test_data( test_data )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d18648bfca7730471fb15e1319557d0aa883346285fa8720fad782c08b20638"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
