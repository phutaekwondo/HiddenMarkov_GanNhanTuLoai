{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "DAUCAU = \",.\"\n",
    "\n",
    "# input and out processing\n",
    "def words_to_word( words ):\n",
    "\treturn \"_\".join(words)\n",
    "def preprocess_sen(sen):\n",
    "\tsen = sen.lower()\n",
    "\tsen = sen.replace(\"!\", \".\")\n",
    "\tsen = sen.replace(\"?\", \".\")\n",
    "\tsen = sen.replace(\";\", \"\")\n",
    "\tsen = sen.replace(\":\", \"\")\n",
    "\tsen = sen.replace(\"%\", \"\")\n",
    "\tsen = sen.replace(\"\\n\", \"\")\n",
    "\n",
    "\t\n",
    "\tfor c in DAUCAU:\n",
    "\t\tsen = sen.replace(c, \" \"+c+\" \")\n",
    "\n",
    "\treturn sen\n",
    "def sen_to_words( sen ):\n",
    "\n",
    "\tdef fullOfSpace( str ):\n",
    "\t\tfor c in str:\n",
    "\t\t\tif c != ' ':\n",
    "\t\t\t\treturn False \n",
    "\t\t\n",
    "\t\treturn True \n",
    "\n",
    "\tsen = preprocess_sen( sen )\n",
    "\n",
    "\tsen_words = [ w for w in sen.split(\" \") if not fullOfSpace(w) ]\n",
    "\n",
    "\t\n",
    "\treturn sen_words\n",
    "def words_and_pos_to_output_sen( sen_words, sen_pos ):\n",
    "\toutput = \"\"\n",
    "\tn = len( sen_words)\n",
    "\tcomma = ','\n",
    "\tdot = '.'\n",
    "\n",
    "\t# hide pos of ',' and '.'\n",
    "\tfor i in range(n ):\n",
    "\t\tif i ==0 or sen_words[i] in (comma, dot):\n",
    "\t\t\toutput += sen_words[i]\n",
    "\t\telse:\n",
    "\t\t\toutput += ' ' + sen_words[i]\n",
    "\t\t\n",
    "\t\tif not sen_words[i] in (comma,dot):\n",
    "\t\t\toutput += \"/\" + sen_pos[i].upper()\n",
    "\n",
    "\n",
    "\n",
    "\treturn output\n",
    "def file_to_tagged_data( path ):\n",
    "\tfile = open(path, \"r\", encoding=\"utf8\")\n",
    "\ttext = file.readlines()\n",
    "\n",
    "\ttagged_data = []\n",
    "\n",
    "\tfor line in text:\n",
    "\t\ttagged_line = []\n",
    "\n",
    "\t\tline_words = sen_to_words( line )\n",
    "\n",
    "\t\tfor w in line_words:\n",
    "\t\t\tif not \"/\" in w:\n",
    "\t\t\t\ttagged_line.append((w,w))\n",
    "\t\t\telse:\n",
    "\t\t\t\ts = w.split(\"/\")\n",
    "\t\t\t\ttagged_line.append((s[0], s[1]))\n",
    "\n",
    "\t\ttagged_data.append( tagged_line )\n",
    "\n",
    "\treturn tagged_data\n",
    "\n",
    "#tach tu bang thuat toan Longest matching\n",
    "def Longest_matching( sen, words_list):\n",
    "\twords = sen_to_words(sen)\n",
    "\ttokens = []\n",
    "\tn = len( words )\n",
    "\ts = 0\n",
    "\twhile s < n :\n",
    "\t\te = n\n",
    "\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\twhile ( not word in words_list ) and e>s+1:\n",
    "\t\t\te -= 1\n",
    "\t\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\ttokens.append( word )\n",
    "\t\tif e <= s :\n",
    "\t\t\ts += 1\n",
    "\t\telse:\n",
    "\t\t\ts = e\n",
    "\n",
    "\treturn tokens\n",
    "\n",
    "#gan nhan tu loai tuyen tinh\n",
    "def find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len(words)\n",
    "\treturn_pos = []\n",
    "\treturn_pro = 1\n",
    "\tfor i in range( n ):\n",
    "\t\tw = words[i]\n",
    "\t\tif w in DAUCAU:\n",
    "\t\t\treturn_pos.append(w)\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\t\tpro = 0\n",
    "\t\t\taccept_pos = \"\"\n",
    "\t\t\tfor pos in accept_tags_list:\n",
    "\t\t\t\ttemp_pro = 1\n",
    "\t\t\t\t#calculate prepos-pos\n",
    "\t\t\t\tx_index = tags_list.index( pos )\n",
    "\t\t\t\ty_index = 0\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\ty_index = len(tags_list)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ty_index = tags_list.index( return_pos[i-1] )\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_markov_matrix[y_index,x_index]\n",
    "\t\t\t\t#calculate pos-word\n",
    "\t\t\t\ty_index = tags_list.index( pos )\n",
    "\t\t\t\tx_index = 0\n",
    "\t\t\t\tif w in words_list:\n",
    "\t\t\t\t\tx_index = words_list.index(w)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\t\t\t\tif temp_pro > pro:\n",
    "\t\t\t\t\tpro = temp_pro\n",
    "\t\t\t\t\taccept_pos = pos\n",
    "\t\t\t\n",
    "\t\t\treturn_pos.append( accept_pos )\n",
    "\t\t\treturn_pro *= pro\n",
    "\n",
    "\treturn return_pos, return_pro\n",
    "\n",
    "#gan nhan tu loai quy hoach dong (de quy) #CANCELED\n",
    "def Probality_words_pos( sen_words, sen_pos, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tif len(sen_words) != len(sen_pos):\n",
    "\t\treturn 0\n",
    "\n",
    "\tpro = 1\n",
    "\tfor i in range( len( sen_pos)):\n",
    "\t\tx_index = tags_list.index( sen_pos[i] )\n",
    "\t\ty_index = 0\n",
    "\t\tif i == 0:\n",
    "\t\t\ty_index = len( tags_list)\n",
    "\t\telse:\n",
    "\t\t\ty_index = tags_list.index( sen_pos[i-1] )\n",
    "\n",
    "\t\tpro *= hidden_markov_matrix[y_index,x_index]\n",
    "\n",
    "\tfor word, pos in zip( sen_words, sen_pos ):\n",
    "\t\ty_index = tags_list.index(pos)\n",
    "\t\tx_index = 0\n",
    "\t\tif word in words_list:\n",
    "\t\t\tx_index = words_list.index( word )\n",
    "\t\telse:\n",
    "\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\tpro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\treturn pro\n",
    "def recur_find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len( words )\n",
    "\n",
    "\tdef recur_find_pos( pos_list,words, n, hidden_markov_matrix, hidden_to_observed_matrix):\n",
    "\t\t# stop\n",
    "\t\tif len(pos_list) == n:\n",
    "\t\t\treturn pos_list, Probality_words_pos( words, pos_list, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\t\n",
    "\t\tpro = 0\n",
    "\t\treturn_pos_list = []\n",
    "\t\tword_index = len(pos_list)\n",
    "\n",
    "\t\taccept_tags_list = []\n",
    "\t\tif words[ word_index ] not in DAUCAU:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [words[word_index]]\n",
    "\n",
    "\t\tfor pos in accept_tags_list:\n",
    "\t\t\tnew_pos_list, new_pro = recur_find_pos( pos_list[:] + [pos], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\t\t\tif new_pro > pro:\n",
    "\t\t\t\treturn_pos_list = new_pos_list\n",
    "\t\t\t\tpro = new_pro\n",
    "\t\t\n",
    "\t\treturn return_pos_list, pro\n",
    "\t\n",
    "\treturn recur_find_pos([], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\n",
    "\t\n",
    "def get_only_tags_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor _, tag in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_only_words_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor tag,_ in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_tags_list_from_tagged_data( tagged_data ):\n",
    "\ttags = []\n",
    "\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor _, tag in line :\n",
    "\t\t\tif not tag in tags:\n",
    "\t\t\t\ttags.append(tag)\n",
    "\t\n",
    "\treturn tags\n",
    "def get_words_list_from_tagged_data( tagged_data ):\n",
    "\twords = []\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor w, _ in line :\n",
    "\t\t\tif not w in words:\n",
    "\t\t\t\twords.append(w)\n",
    "\t\n",
    "\treturn words\n",
    "\n",
    "def Accuracy_on_test_data( test_data ):\n",
    "\ttest_pos = get_only_tags_from_tagged_data(test_data)\n",
    "\ttest_words = get_only_words_from_tagged_data( test_data )\n",
    "\n",
    "\ttotal_n_pos = 0\n",
    "\tfor sen_pos in test_pos:\n",
    "\t\ttotal_n_pos += len(sen_pos)\n",
    "\n",
    "\ttest_sens = []\n",
    "\tfor sen_words in test_words:\n",
    "\t\tsen = \" \".join(sen_words)\n",
    "\t\tsen = sen.replace(\"_\",\" \")\n",
    "\t\ttest_sens.append( sen )\n",
    "\n",
    "\n",
    "\tcorrect = 0\n",
    "\tfor i in range( len( test_sens )):\n",
    "\t\tprint(\"--------------------------------\")\n",
    "\t\ttest_sen_words = Longest_matching( test_sens[i], words_list )\n",
    "\t\tresult_pos, pro = find_pos_for_words( test_sen_words, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\tprint(words_and_pos_to_output_sen( test_sen_words, result_pos))\n",
    "\t\tfor j in range( len(test_pos[i]) ):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tif result_pos[j] == test_pos[i][j] and result_pos[j] not in DAUCAU:\n",
    "\t\t\t\t\tcorrect += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\treturn correct/ total_n_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = file_to_tagged_data( \"train_data.txt\")\n",
    "test_data = file_to_tagged_data( \"test_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden markov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  hidden markov matrix\n",
    "#\n",
    "#  ---------------------------\n",
    "#  \t   |tag0|tag1|...|tagN|\n",
    "#  --------+-------------------\n",
    "#  tag0    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  ...     |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  tagN    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  <s>     |    |    |   |    |\n",
    "#  ----------------------------\n",
    "\n",
    "\n",
    "#  hidden to observed matrix\n",
    "#\n",
    "#  --------------------------------------+\n",
    "#  \t   |word0|word1|...|wordM|unknown|\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tag0    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  ...     |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tagN    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words list (dictionary), tags list, tags chains\n",
    "words_list = get_words_list_from_tagged_data( tagged_data )+ [\"unknown\"]\n",
    "tags = get_only_tags_from_tagged_data( tagged_data )\n",
    "tags_list = get_tags_list_from_tagged_data(tagged_data)\n",
    "\n",
    "\n",
    "# create new matrix reference to hidden markov chain\n",
    "n = len(tags_list)\n",
    "hidden_markov_matrix = np.zeros((n+1,n))\n",
    "for line in tags:\n",
    "\ti = 0\n",
    "\tn = len( line )\n",
    "\twhile i < n:\n",
    "\t\tif i == 0:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = len(tags_list)\n",
    "\t\telse:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = tags_list.index(line[i-1])\n",
    "\n",
    "\t\thidden_markov_matrix[y_index,x_index] += 1\n",
    "\t\ti+=1 \n",
    "\n",
    "# create matrix reference to hidden-to-observed connect\n",
    "n_tags = len(tags_list)\n",
    "n_words = len(words_list)\n",
    "\n",
    "hidden_to_observed_matrix = np.zeros((n_tags,n_words+1))\n",
    "for line in tagged_data:\n",
    "\tfor w, tag in line :\n",
    "\t\ty_index = tags_list.index(tag)\n",
    "\t\tx_index = words_list.index(w)\n",
    "\n",
    "\t\thidden_to_observed_matrix[y_index,x_index] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smooth and calculate probality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth\n",
    "hidden_markov_matrix = hidden_markov_matrix + 0.1\n",
    "hidden_to_observed_matrix = hidden_to_observed_matrix + 0.1\n",
    "\n",
    "#calculate probality\n",
    "for i in range( hidden_markov_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_markov_matrix[i] )\n",
    "\thidden_markov_matrix[i] = hidden_markov_matrix[i] / total\n",
    "\n",
    "for i in range( hidden_to_observed_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_to_observed_matrix[i] )\n",
    "\thidden_to_observed_matrix[i] = hidden_to_observed_matrix[i] / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tôi', 'yêu', 'bóng_đá', 'và', 'đất_nước']\n",
      "['n', 'v', 'n', 'q', 'n']\n",
      "tôi/N yêu/V bóng_đá/N và/Q đất_nước/N\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "sen = \"Tôi yêu bóng đá và đất nước\"\n",
    "sen_words = Longest_matching( sen , words_list)\n",
    "sen_pos, probality = find_pos_for_words( sen_words, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\n",
    "print( sen_words )\n",
    "print( sen_pos )\n",
    "print(words_and_pos_to_output_sen( sen_words, sen_pos ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "hôm_nay/W gia_đình/N hạnh_phúc/A.\n",
      "--------------------------------\n",
      "anh/N chỉ/P thích/V em/N thôi/A.\n",
      "--------------------------------\n",
      "tôi/N đang/P chơi/V bóng_đá/N.\n",
      "--------------------------------\n",
      "tôi/N yêu/V hoa_hồng/N.\n",
      "--------------------------------\n",
      "tôi/N thường_xuyên/W ăn/V dưa_hấu/N.\n",
      "--------------------------------\n",
      "học_tập/V để/Q bản_thân/N không/P thua_thiệt/V với/Q bạn_bè/N.\n",
      "--------------------------------\n",
      "tôi/N ghét/A chơi/V bóng/P.\n",
      "--------------------------------\n",
      "ai/D cũng/P tắm/V.\n",
      "--------------------------------\n",
      "tết_nguyên_đán/N là/V ngày/N đoàn_tụ/V gia_đình/N.\n",
      "--------------------------------\n",
      "đây/D là/V khoảng/L thời_gian/N thiêng_liêng/A của/Q người_việt/N nam/A.\n",
      "--------------------------------\n",
      "mọi/L người/N trong/Q gia_đình/N chúc_tết/V ông_bà/N.\n",
      "--------------------------------\n",
      "ngày/N để/Q tưởng_nhớ/V những/L người_thân/N đã/P mất/V.\n",
      "--------------------------------\n",
      "thầy_thuốc/N không_bao_giờ/P lựa_chọn/V món_ăn/N ngon/A.\n",
      "--------------------------------\n",
      "trong/Q dịp/N tết_dương_lịch/N, người_việt/N sắm_sửa/V hai/M mươi/N mốt/A mâm/N ngũ_quả/N.\n",
      "--------------------------------\n",
      "gia_đình/N rất/P quan_trọng/A đối_với/Q mỗi/L con_người/N.\n",
      "--------------------------------\n",
      "ngày/N gia_đình/N dọn_dẹp/V là/V ngày/N mười_chín/M tháng/N một/M hàng_năm/N.\n",
      "--------------------------------\n",
      "nén_hương/N bắt_đầu/V quyện/V vào/Q không_khí/N thiêng_liêng/A ngày/N tết/N.\n",
      "--------------------------------\n",
      "tết_nguyên_đán/N là/V dịp/N ý_nghĩa/N để/Q tưởng_nhớ/V tổ_tiên/N.\n",
      "--------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.768595041322314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Accuracy_on_test_data( test_data ):\n",
    "\ttest_pos = get_only_tags_from_tagged_data(test_data)\n",
    "\ttest_words = get_only_words_from_tagged_data( test_data )\n",
    "\n",
    "\ttotal_n_pos = 0\n",
    "\tfor sen_pos in test_pos:\n",
    "\t\ttotal_n_pos += len(sen_pos)\n",
    "\n",
    "\ttest_sens = []\n",
    "\tfor sen_words in test_words:\n",
    "\t\tsen = \" \".join(sen_words)\n",
    "\t\tsen = sen.replace(\"_\",\" \")\n",
    "\t\ttest_sens.append( sen )\n",
    "\n",
    "\n",
    "\tcorrect = 0\n",
    "\tfor i in range( len( test_sens )):\n",
    "\t\tprint(\"--------------------------------\")\n",
    "\t\ttest_sen_words = Longest_matching( test_sens[i], words_list )\n",
    "\t\tresult_pos, pro = find_pos_for_words( test_sen_words, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\tprint(words_and_pos_to_output_sen( test_sen_words, result_pos))\n",
    "\t\tfor j in range( len(test_pos[i]) ):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tif result_pos[j] == test_pos[i][j] and result_pos[j] not in DAUCAU:\n",
    "\t\t\t\t\tcorrect += 1\n",
    "\t\t\texcept:\n",
    "\t\t\t\tpass\n",
    "\n",
    "\treturn correct/ total_n_pos\n",
    "\n",
    "Accuracy_on_test_data( test_data )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d18648bfca7730471fb15e1319557d0aa883346285fa8720fad782c08b20638"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
