{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gán Nhãn Từ Loại (Hidden Markov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhóm:\n",
    "\n",
    "19522020 - Lại Nguyễn Vĩnh Phú\n",
    "\n",
    "19522447 - Trương Thế Trương"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import underthesea\n",
    "\n",
    "DAUCAU = \",;-.?!:…\"\n",
    "DAUCAU_POS = \",,......\"\n",
    "DAUCAU_POS = \",;-.?!:…\"\n",
    "DAUCAU_POS = \".\" * len(DAUCAU)\n",
    "\n",
    "\n",
    "# input and out processing\n",
    "def words_to_word( words ):\n",
    "\treturn \"_\".join(words)\n",
    "def preprocess_sen(sen):\n",
    "\tsen = sen.lower()\n",
    "\tsen = sen.replace(\"%\", \"\")\n",
    "\tsen = sen.replace(\"\\n\", \"\")\n",
    "\n",
    "\t\n",
    "\tfor c in DAUCAU:\n",
    "\t\tsen = sen.replace(c, \" \"+c+\" \")\n",
    "\n",
    "\treturn sen\n",
    "def fullOfSpace( str ):\n",
    "\tfor c in str:\n",
    "\t\tif c not in ' \\n':\n",
    "\t\t\treturn False \n",
    "\t\n",
    "\treturn True \n",
    "def sen_to_words( sen ):\n",
    "\n",
    "\n",
    "\tsen = preprocess_sen( sen )\n",
    "\n",
    "\tsen_words = [ w for w in sen.split(\" \") if not fullOfSpace(w) ]\n",
    "\n",
    "\t\n",
    "\treturn sen_words\n",
    "def words_and_pos_to_output_sen( sen_words, sen_pos ):\n",
    "\toutput = \"\"\n",
    "\tn = len( sen_words)\n",
    "\tcomma = ','\n",
    "\tdot = '.'\n",
    "\n",
    "\t# hide pos of ',' and '.'\n",
    "\tfor i in range(n ):\n",
    "\t\tif i ==0 or sen_words[i] in (comma, dot):\n",
    "\t\t\toutput += sen_words[i]\n",
    "\t\telse:\n",
    "\t\t\toutput += ' ' + sen_words[i]\n",
    "\t\t\n",
    "\t\tif not sen_words[i] in (comma,dot):\n",
    "\t\t\toutput += \"/\" + sen_pos[i].upper()\n",
    "\n",
    "\n",
    "\n",
    "\treturn output\n",
    "def file_to_tagged_data( path ):\n",
    "\tfile = open(path, \"r\", encoding=\"utf8\")\n",
    "\ttext = file.readlines()\n",
    "\n",
    "\ttagged_data = []\n",
    "\n",
    "\tfor line in text:\n",
    "\t\tif not fullOfSpace( line ):\n",
    "\t\t\ttagged_line = []\n",
    "\n",
    "\t\t\tline_words = sen_to_words( line )\n",
    "\n",
    "\t\t\tfor w in line_words:\n",
    "\t\t\t\tif w in DAUCAU:\n",
    "\t\t\t\t\tDAUCAU_index = DAUCAU.index(w)\n",
    "\t\t\t\t\ttagged_line.append((w,DAUCAU_POS[DAUCAU_index]))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ts = w.split(\"/\")\n",
    "\t\t\t\t\ttagged_line.append((s[0], s[1]))\n",
    "\n",
    "\t\t\ttagged_data.append( tagged_line )\n",
    "\n",
    "\treturn tagged_data\n",
    "\n",
    "#tach tu bang thuat toan Longest matching\n",
    "def Longest_matching( sen, words_list):\n",
    "\tmax_item_in_a_word = max([len(w.split('_')) for w in words_list])\n",
    "\twords = sen_to_words(sen)\n",
    "\ttokens = []\n",
    "\tn = len( words )\n",
    "\ts = 0\n",
    "\twhile s < n :\n",
    "\t\te = s + max_item_in_a_word\n",
    "\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\twhile ( not word in words_list ) and e>s+1:\n",
    "\t\t\te -= 1\n",
    "\t\t\tword = words_to_word( words[s:e] )\n",
    "\n",
    "\t\ttokens.append( word )\n",
    "\t\tif e <= s :\n",
    "\t\t\ts += 1\n",
    "\t\telse:\n",
    "\t\t\ts = e\n",
    "\n",
    "\treturn tokens\n",
    "\n",
    "#gan nhan tu loai tuyen tinh\n",
    "def find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len(words)\n",
    "\treturn_pos = []\n",
    "\treturn_pro = 1\n",
    "\tfor i in range( n ):\n",
    "\t\tw = words[i]\n",
    "\t\tif w in DAUCAU:\n",
    "\t\t\tDAUCAU_index = DAUCAU.index(w)\n",
    "\t\t\treturn_pos.append(DAUCAU_POS[DAUCAU_index])\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\t\tpro = 0\n",
    "\t\t\taccept_pos = \"\"\n",
    "\t\t\tfor pos in accept_tags_list:\n",
    "\t\t\t\ttemp_pro = 1\n",
    "\t\t\t\t#calculate prepos-pos\n",
    "\t\t\t\tx_index = tags_list.index( pos )\n",
    "\t\t\t\ty_index = 0\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\ty_index = len(tags_list)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ty_index = tags_list.index( return_pos[i-1] )\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_markov_matrix[y_index,x_index]\n",
    "\t\t\t\t#calculate pos-word\n",
    "\t\t\t\ty_index = tags_list.index( pos )\n",
    "\t\t\t\tx_index = 0\n",
    "\t\t\t\tif w in words_list:\n",
    "\t\t\t\t\tx_index = words_list.index(w)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\t\t\ttemp_pro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\t\t\t\tif temp_pro > pro:\n",
    "\t\t\t\t\tpro = temp_pro\n",
    "\t\t\t\t\taccept_pos = pos\n",
    "\t\t\t\n",
    "\t\t\treturn_pos.append( accept_pos )\n",
    "\t\t\treturn_pro *= pro\n",
    "\n",
    "\treturn return_pos, return_pro\n",
    "\n",
    "#gan nhan tu loai quy hoach dong (de quy) #CANCELED\n",
    "def Probality_words_pos( sen_words, sen_pos, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tif len(sen_words) != len(sen_pos):\n",
    "\t\treturn 0\n",
    "\n",
    "\tpro = 1\n",
    "\tfor i in range( len( sen_pos)):\n",
    "\t\tx_index = tags_list.index( sen_pos[i] )\n",
    "\t\ty_index = 0\n",
    "\t\tif i == 0:\n",
    "\t\t\ty_index = len( tags_list)\n",
    "\t\telse:\n",
    "\t\t\ty_index = tags_list.index( sen_pos[i-1] )\n",
    "\n",
    "\t\tpro *= hidden_markov_matrix[y_index,x_index]\n",
    "\n",
    "\tfor word, pos in zip( sen_words, sen_pos ):\n",
    "\t\ty_index = tags_list.index(pos)\n",
    "\t\tx_index = 0\n",
    "\t\tif word in words_list:\n",
    "\t\t\tx_index = words_list.index( word )\n",
    "\t\telse:\n",
    "\t\t\tx_index = len(words_list)\n",
    "\n",
    "\t\tpro *= hidden_to_observed_matrix[y_index, x_index]\n",
    "\n",
    "\treturn pro\n",
    "def recur_find_pos_for_words( words, hidden_markov_matrix, hidden_to_observed_matrix ):\n",
    "\tn = len( words )\n",
    "\n",
    "\tdef recur_find_pos( pos_list,words, n, hidden_markov_matrix, hidden_to_observed_matrix):\n",
    "\t\t# stop\n",
    "\t\tif len(pos_list) == n:\n",
    "\t\t\treturn pos_list, Probality_words_pos( words, pos_list, hidden_markov_matrix, hidden_to_observed_matrix )\n",
    "\t\t\n",
    "\t\tpro = 0\n",
    "\t\treturn_pos_list = []\n",
    "\t\tword_index = len(pos_list)\n",
    "\n",
    "\t\taccept_tags_list = []\n",
    "\t\tif words[ word_index ] not in DAUCAU:\n",
    "\t\t\taccept_tags_list = [ tag for tag in tags_list if tag not in DAUCAU ]\n",
    "\t\telse:\n",
    "\t\t\taccept_tags_list = [words[word_index]]\n",
    "\n",
    "\t\tfor pos in accept_tags_list:\n",
    "\t\t\tnew_pos_list, new_pro = recur_find_pos( pos_list[:] + [pos], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\t\t\tif new_pro > pro:\n",
    "\t\t\t\treturn_pos_list = new_pos_list\n",
    "\t\t\t\tpro = new_pro\n",
    "\t\t\n",
    "\t\treturn return_pos_list, pro\n",
    "\t\n",
    "\treturn recur_find_pos([], words, n, hidden_markov_matrix, hidden_to_observed_matrix)\n",
    "\n",
    "#viterbi\n",
    "def Viterbi_find_pos_for_words( sen_words ):\n",
    "\tif len(sen_words) <= 0:\n",
    "\t\treturn [],1\n",
    "\t# viterbi\n",
    "\tpath_matrix = [[(\"\",0) for i in range((len(sen_words)))] for i in range(len(tags_list)) ]\n",
    "\n",
    "\tfor x in range( len(sen_words)):\n",
    "\t\tif x == 0:\n",
    "\t\t\tfor y in range(len(tags_list)):\n",
    "\t\t\t\tpath_matrix[y][x] = (\"<s>\", 0)\n",
    "\n",
    "\t\t\taccept_poses = []\n",
    "\t\t\tif sen_words[x] not in DAUCAU:\n",
    "\t\t\t\taccept_poses = [t for t in tags_list if t not in DAUCAU]\n",
    "\t\t\telse:\n",
    "\t\t\t\taccept_poses = [t for t in tags_list if t in DAUCAU]\n",
    "\n",
    "\t\t\tfor pos in accept_poses:\n",
    "\t\t\t\t\tpro = 1\n",
    "\t\t\t\t\t#prepos - pos\n",
    "\t\t\t\t\ty_index = len(tags_list)\n",
    "\t\t\t\t\tx_index = tags_list.index(pos)\n",
    "\t\t\t\t\tpro *= hidden_markov_matrix[y_index,x_index]\n",
    "\n",
    "\t\t\t\t\t#pos - word\n",
    "\t\t\t\t\ty_index = tags_list.index(pos)\n",
    "\t\t\t\t\tx_index = 0\n",
    "\t\t\t\t\tif sen_words[x] not in words_list:\n",
    "\t\t\t\t\t\tx_index = len(words_list)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tx_index = words_list.index(sen_words[x])\n",
    "\n",
    "\t\t\t\t\tpro *= hidden_to_observed_matrix[y_index,x_index]\n",
    "\n",
    "\t\t\t\t\ty = tags_list.index(pos)\n",
    "\t\t\t\t\tpath_matrix[y][x] = (path_matrix[y][x][0], pro) \n",
    "\n",
    "\t\telse:\n",
    "\t\t\taccept_poses=[]\n",
    "\t\t\tif sen_words[x] not in DAUCAU:\n",
    "\t\t\t\taccept_poses = [t for t in tags_list if t not in DAUCAU]\n",
    "\t\t\telse:\n",
    "\t\t\t\taccept_poses = [t for t in tags_list if t in DAUCAU]\n",
    "\n",
    "\t\t\tfor pos in accept_poses:\n",
    "\t\t\t\ty = tags_list.index(pos)\n",
    "\n",
    "\t\t\t\t#pos - word\n",
    "\t\t\t\ty_index = tags_list.index(pos)\n",
    "\t\t\t\tx_index = 0\n",
    "\t\t\t\tif sen_words[x] not in words_list:\n",
    "\t\t\t\t\tx_index = len(words_list)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tx_index = words_list.index(sen_words[x])\n",
    "\n",
    "\t\t\t\tpos_word_pro = hidden_to_observed_matrix[y_index,x_index]\n",
    "\n",
    "\t\t\t\tfor pre_pos in tags_list:\n",
    "\t\t\t\t\t#prepos - pos\n",
    "\t\t\t\t\tpre_pos_index = tags_list.index(pre_pos)\n",
    "\t\t\t\t\tpro = pos_word_pro * path_matrix[pre_pos_index][x-1][1]\n",
    "\t\t\t\t\ty_index = tags_list.index(pre_pos)\n",
    "\t\t\t\t\tx_index = tags_list.index(pos)\n",
    "\t\t\t\t\tpro *= hidden_markov_matrix[y_index,x_index]\n",
    "\n",
    "\t\t\t\t\tif path_matrix[y][x][1] < pro:\n",
    "\t\t\t\t\t\tpath_matrix[y][x] = (pre_pos, pro)\n",
    "\t\t\t\t\t\n",
    "\t#FOR SLIDE\n",
    "\n",
    "\t# find the path\n",
    "\tx = len(sen_words) -1\n",
    "\ty = 0\n",
    "\tpro = 0\n",
    "\tfor i in range(len(tags_list)):\n",
    "\t\tif path_matrix[i][x][1] > pro:\n",
    "\t\t\tpro = path_matrix[i][x][1]\n",
    "\t\t\ty = i\n",
    "\n",
    "\treturn_poses = [tags_list[y]]\n",
    "\twhile x > 0:\n",
    "\t\tadd_pos = path_matrix[y][x][0]\n",
    "\t\treturn_poses = [add_pos] + return_poses\n",
    "\t\ty = tags_list.index(add_pos)\n",
    "\n",
    "\t\tx-=1\n",
    "\n",
    "\treturn return_poses, pro\n",
    "\t\n",
    "def get_words_count_from_tagged_data(tagged_data):\n",
    "\twords = {} \n",
    "\tfor line in tagged_data:\n",
    "\t\tfor w, _ in line :\n",
    "\t\t\tif not w in words.keys():\n",
    "\t\t\t\twords[w] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[w] += 1\n",
    "\t\n",
    "\treturn words\n",
    "def get_tags_count_from_tagged_data(tagged_data):\n",
    "\twords = {} \n",
    "\tfor line in tagged_data:\n",
    "\t\tfor _, w in line :\n",
    "\t\t\tif not w in words.keys():\n",
    "\t\t\t\twords[w] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\twords[w] += 1\n",
    "\t\n",
    "\treturn words\n",
    "def get_only_tags_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor _, tag in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_only_words_from_tagged_data ( tagged_data ):\n",
    "\ttags = []\n",
    "\tfor line in tagged_data :\n",
    "\t\ttags_line = []\n",
    "\t\tfor tag,_ in line:\n",
    "\t\t\ttags_line.append(tag)\n",
    "\t\t\n",
    "\t\ttags.append( tags_line )\n",
    "\t\n",
    "\treturn tags\n",
    "def get_tags_list_from_tagged_data( tagged_data ):\n",
    "\ttags = []\n",
    "\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor _, tag in line :\n",
    "\t\t\tif not tag in tags:\n",
    "\t\t\t\ttags.append(tag)\n",
    "\t\n",
    "\treturn tags\n",
    "def get_words_list_from_tagged_data( tagged_data ):\n",
    "\twords = []\n",
    "\tfor line in tagged_data:\n",
    "\t\tfor w, _ in line :\n",
    "\t\t\tif not w in words:\n",
    "\t\t\t\twords.append(w)\n",
    "\t\n",
    "\treturn words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = file_to_tagged_data( \"train_data.txt\")\n",
    "test_data = file_to_tagged_data( \"test_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden markov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  hidden markov matrix\n",
    "#\n",
    "#  ---------------------------\n",
    "#  \t   |tag0|tag1|...|tagN|\n",
    "#  --------+-------------------\n",
    "#  tag0    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  ...     |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  tagN    |    |    |   |    |\n",
    "#  --------+----+----+---+----+\n",
    "#  <s>     |    |    |   |    |\n",
    "#  ----------------------------\n",
    "\n",
    "\n",
    "#  hidden to observed matrix\n",
    "#\n",
    "#  --------------------------------------+\n",
    "#  \t   |word0|word1|...|wordM|unknown|\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tag0    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  ...     |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+\n",
    "#  tagN    |     |     |   |     |       |\n",
    "#  --------+-----+-----+---+-----+-------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words list (dictionary), tags list, tags chains\n",
    "words_list = get_words_list_from_tagged_data( tagged_data )\n",
    "tags = get_only_tags_from_tagged_data( tagged_data )\n",
    "tags_list = get_tags_list_from_tagged_data(tagged_data)\n",
    "\n",
    "\n",
    "# create new matrix reference to hidden markov chain\n",
    "n = len(tags_list)\n",
    "hidden_markov_matrix = np.zeros((n+1,n))\n",
    "for line in tags:\n",
    "\ti = 0\n",
    "\tn = len( line )\n",
    "\twhile i < n:\n",
    "\t\tif i == 0:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = len(tags_list)\n",
    "\t\telse:\n",
    "\t\t\tx_index = tags_list.index(line[i])\n",
    "\t\t\ty_index = tags_list.index(line[i-1])\n",
    "\n",
    "\t\thidden_markov_matrix[y_index,x_index] += 1\n",
    "\t\ti+=1 \n",
    "\n",
    "# create matrix reference to hidden-to-observed connect\n",
    "n_tags = len(tags_list)\n",
    "n_words = len(words_list)\n",
    "\n",
    "\n",
    "hidden_to_observed_matrix = np.zeros((n_tags,n_words+1))\n",
    "for line in tagged_data:\n",
    "\tfor w, tag in line :\n",
    "\t\ty_index = tags_list.index(tag)\n",
    "\t\tx_index = words_list.index(w)\n",
    "\n",
    "\n",
    "\t\thidden_to_observed_matrix[y_index,x_index] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smooth and calculate probality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smooth\n",
    "smooth_value = 0.1\n",
    "hidden_markov_matrix = hidden_markov_matrix + smooth_value\n",
    "hidden_to_observed_matrix = hidden_to_observed_matrix + smooth_value\n",
    "\n",
    "#calculate probality\n",
    "for i in range( hidden_markov_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_markov_matrix[i] )\n",
    "\thidden_markov_matrix[i] = hidden_markov_matrix[i] / total\n",
    "\n",
    "for i in range( hidden_to_observed_matrix.shape[0] ):\n",
    "\ttotal = np.sum( hidden_to_observed_matrix[i] )\n",
    "\thidden_to_observed_matrix[i] = hidden_to_observed_matrix[i] / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'v', 'a', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tôi/N yêu/V nước/A.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "sen = \"Tôi yêu quê hương, đất nước nhiều hoa hồng.\"\n",
    "sen = \"tết nguyên đáng là dịp ý nghĩa để tưởng nhớ tổ tiên.\"\n",
    "sen = \",.\"\n",
    "sen = \"tôi yêu nước.\"\n",
    "sen_words = Longest_matching( sen , words_list)\n",
    "\n",
    "\n",
    "sen_pos,_ = Viterbi_find_pos_for_words(sen_words)\n",
    "print(sen_pos)\n",
    "words_and_pos_to_output_sen( sen_words, sen_pos )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc one sen\n",
    "def Accuracy_on_test_data( test_data ):\n",
    "\ttest_pos = get_only_tags_from_tagged_data(test_data)\n",
    "\ttest_words = get_only_words_from_tagged_data( test_data )\n",
    "\n",
    "\ttotal_n_pos = 0\n",
    "\tfor sen_pos in test_pos:\n",
    "\t\ttotal_n_pos += len(sen_pos)\n",
    "\n",
    "\ttest_sens = []\n",
    "\tfor sen_words in test_words:\n",
    "\t\tsen = \" \".join(sen_words)\n",
    "\t\tsen = sen.replace(\"_\",\" \")\n",
    "\t\ttest_sens.append( sen )\n",
    "\n",
    "\n",
    "\tcorrect = 0\n",
    "\tfor i in range( len( test_sens )):\n",
    "\t\t\n",
    "\t\tpre_sen_words = Longest_matching( test_sens[i], words_list )\n",
    "\t\tresult_pos, _ = Viterbi_find_pos_for_words(pre_sen_words)\n",
    "\n",
    "\t\tcorrect += Correct_on_one_sen( pre_sen_words, result_pos, test_words[i], test_pos[i])\n",
    "\n",
    "\t\tprint( words_and_pos_to_output_sen(test_words[i], test_pos[i]))\n",
    "\t\tprint( words_and_pos_to_output_sen(pre_sen_words,result_pos))\n",
    "\t\tprint( \"----------------------\")\n",
    "\t\n",
    "\treturn correct/total_n_pos\n",
    "\t\n",
    "\n",
    "def Correct_on_one_sen( pre_sen_words, pre_pos, truth_sen_words, truth_pos):\n",
    "\tpre_words_size = [len(pre.split(\"_\")) for pre in pre_sen_words if pre not in DAUCAU] \n",
    "\ttru_words_size = [len(tru.split(\"_\")) for tru in truth_sen_words if tru not in DAUCAU]\n",
    "\n",
    "\tcorrect = 0\n",
    "\n",
    "\tfor i in range( len(tru_words_size) ):\n",
    "\t\ttru_start = sum( tru_words_size[:i] )\n",
    "\t\tj=0\n",
    "\t\tpre_start = 0\n",
    "\t\twhile pre_start < tru_start:\n",
    "\t\t\tj+=1\n",
    "\t\t\tpre_start = sum( pre_words_size[:j])\n",
    "\n",
    "\t\tif pre_start == tru_start:\n",
    "\t\t\tif pre_pos[j] == truth_pos[i] and pre_sen_words[j] == truth_sen_words[i] and (truth_sen_words[i] not in DAUCAU): \n",
    "\t\t\t\tcorrect += 1\n",
    "\n",
    "\treturn correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 3\n"
     ]
    }
   ],
   "source": [
    "test_words_list = get_words_list_from_tagged_data( test_data )\n",
    "unknown_count = 0\n",
    "for w in test_words_list:\n",
    "\tif w not in words_list:\n",
    "\t\tunknown_count += 1\n",
    "\n",
    "print( len(test_words_list ), unknown_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hôm_nay/N gia_đình/N hạnh_phúc/A.\n",
      "hôm_nay/N gia_đình/N hạnh_phúc/A.\n",
      "----------------------\n",
      "anh/N chỉ/R thích/V em/N thôi/I.\n",
      "anh/N chỉ/R thích/V em/N thôi/A.\n",
      "----------------------\n",
      "tôi/N đang/R chơi/V bóng_đá/N.\n",
      "tôi/N đang/R chơi/V bóng_đá/N.\n",
      "----------------------\n",
      "tôi/N yêu/V hoa_hồng/N.\n",
      "tôi/N yêu/V hoa_hồng/N.\n",
      "----------------------\n",
      "tôi/N thường_xuyên/A ăn/V dưa_hấu/N.\n",
      "tôi/N thường_xuyên/A ăn/V dưa_hấu/N.\n",
      "----------------------\n",
      "học_tập/V để/C bản_thân/N không/R thua_thiệt/V với/C bạn_bè/N.\n",
      "học_tập/V để/C bản_thân/N không/R thua_thiệt/V với/C bạn_bè/N.\n",
      "----------------------\n",
      "tôi/N ghét/V chơi/V bóng/N.\n",
      "tôi/N ghét/R chơi/V bóng/A.\n",
      "----------------------\n",
      "ai/P cũng/R tắm/V.\n",
      "ai/P cũng/R tắm/V.\n",
      "----------------------\n",
      "tết_nguyên_đán/N là/V ngày/N đoàn_tụ/V gia_đình/N.\n",
      "tết_nguyên_đán/N là/V ngày/N đoàn_tụ/V gia_đình/N.\n",
      "----------------------\n",
      "đây/P là/V khoảng/N thời_gian/N thiêng_liêng/A của/E người/N việt_nam/N.\n",
      "đây/P là/V khoảng/N thời_gian/N thiêng_liêng/A của/E người/N việt_nam/N.\n",
      "----------------------\n",
      "mọi/D người/N trong/C gia_đình/N chúc/V tết/N ông_bà/N.\n",
      "mọi/D người/N trong/C gia_đình/N chúc/V tết/N ông_bà/N.\n",
      "----------------------\n",
      "ngày/N để/C tưởng_nhớ/V những/D người_thân/N đã/R mất/V.\n",
      "ngày/N để/C tưởng_nhớ/V những/D người_thân/N đã/R mất/V.\n",
      "----------------------\n",
      "thầy_thuốc/N không/R bao_giờ/P lựa_chọn/V món/N ăn/V ngon/A.\n",
      "thầy_thuốc/N không/R bao_giờ/P lựa_chọn/V món/N ăn/V ngon/A.\n",
      "----------------------\n",
      "trong/E dịp/N tết_dương_lịch/N, người/N việt/N sắm_sửa/V hai_mươi_mốt/M mâm/N ngũ_quả/N.\n",
      "trong/C dịp/N tết_dương_lịch/N, người/N việt/N sắm_sửa/V hai/M mươi/N mốt/C mâm/N ngũ_quả/N.\n",
      "----------------------\n",
      "gia_đình/N rất/R quan_trọng/A đối_với/C mỗi/D con_người/N.\n",
      "gia_đình/N rất/R quan_trọng/A đối_với/C mỗi/D con_người/N.\n",
      "----------------------\n",
      "ngày/N gia_đình/N dọn_dẹp/V là/V ngày/N mười_chín/M tháng/N một/M hằng/R năm/N.\n",
      "ngày/N gia_đình/N dọn_dẹp/V là/V ngày/N mười_chín/M tháng/N một/M hằng/N năm/N.\n",
      "----------------------\n",
      "nén/N hương/N bắt_đầu/V quyện/V vào/E không_khí/N thiêng_liêng/A ngày/N tết/N.\n",
      "nén/N hương/N bắt_đầu/V quyện/V vào/E không_khí/N thiêng_liêng/A ngày/N tết/N.\n",
      "----------------------\n",
      "tết_nguyên_đán/N là/V dịp/N ý_nghĩa/N để/C tưởng_nhớ/V tổ_tiên/N.\n",
      "tết_nguyên_đán/N là/V dịp/N ý_nghĩa/N để/C tưởng_nhớ/V tổ_tiên/N.\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7952755905511811"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_on_test_data( test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gia_đình/N là/V tổ_ấm/N hạnh_phúc/A.\n",
      "gia_đình/N là/V tổ_ấm/N hạnh_phúc/A.\n",
      "----------------------\n",
      "hôm_nay/N trời/N đẹp/A quá/R.\n",
      "hôm_nay/N trời/N đẹp/A quá/R.\n",
      "----------------------\n",
      "tôi/N thua_thiệt/V với/C bạn_bè/N.\n",
      "tôi/N thua_thiệt/V với/C bạn_bè/N.\n",
      "----------------------\n",
      "ba/N là/V người/N đàn_ông/N trụ_cột/N trong/C gia_đình/N.\n",
      "ba/N là/V người/N đàn_ông/N trụ_cột/N trong/C gia_đình/N.\n",
      "----------------------\n",
      "bố_mẹ/N là/V tuyệt_vời/A nhất/R đối_với/C chúng_ta/P.\n",
      "bố_mẹ/N là/V tuyệt_vời/A nhất/R đối_với/C chúng_ta/P.\n",
      "----------------------\n",
      "hoa_hồng/N là/V một/M loài/N hoa/N đẹp/A.\n",
      "hoa_hồng/N là/V một/M loài/N hoa/N đẹp/A.\n",
      "----------------------\n",
      "tôi/P yêu/V quê_hương/N, đất_nước/N.\n",
      "tôi/N yêu/V quê_hương/N, đất_nước/N.\n",
      "----------------------\n",
      "tiếng/N việt/N cực_kỳ/R phong_phú/A, có_thể/R nói/V là/V phức_tạp/A trong/C cấu_tạo/N và/C cả/P ngữ_nghĩa/N.\n",
      "tiếng/N việt/N cực_kỳ/R phong_phú/A, có_thể/R nói/V là/V phức_tạp/A trong/C cấu_tạo/N và/C cả/P ngữ_nghĩa/I.\n",
      "----------------------\n",
      "ai/P cũng/R có/V tổ_tiên/N, cội_nguồn/N để/C nhớ/V.\n",
      "ai/P cũng/R có/V tổ_tiên/N, cội_nguồn/N để/C nhớ/V.\n",
      "----------------------\n",
      "máy_tính/N rất/Q quan_trọng/A, đặc_biệt/A là/V đối_với/C sinh_viên/N.\n",
      "máy_tính/N rất/R quan_trọng/A, đặc_biệt/A là/V đối_với/C sinh_viên/N.\n",
      "----------------------\n",
      "xe_máy/N là/V phương_tiện/N lưu_thông/V, còn/R điện_thoại/N là/V phương_tiện/N liên_lạc/V.\n",
      "xe_máy/N là/V phương_tiện/N lưu_thông/V, còn/R điện_thoại/R là/V phương_tiện/N liên_lạc/V.\n",
      "----------------------\n",
      "chàng_trai/N bơ_vơ/A từ/E xa/A trong/C tim/N hụt_hẫn/A như/C mất/V một/M thứ/N gì/P.\n",
      "chàng_trai/N bơ_vơ/A từ/E xa/A trong/C tim/N hụt_hẫn/A như/C mất/V một/M thứ/N gì/P.\n",
      "----------------------\n",
      "chăm_chỉ/A đọc/V sách/N để/C hoàn_thiện/V bản_thân/N.\n",
      "chăm_chỉ/N đọc/V sách/N để/C hoàn_thiện/V bản_thân/N.\n",
      "----------------------\n",
      "học_tập/V, học_hỏi/V để/C không/R ngừng/V nâng/V cao/A bản_thân/N.\n",
      "học_tập/O, học_hỏi/V để/C không/R ngừng/V nâng/V cao/A bản_thân/N.\n",
      "----------------------\n",
      "đường_sá/N sài_gòn/N hôm_nay/N đông_đúc/A.\n",
      "đường_sá/N sài_gòn/N hôm_nay/N đông_đúc/A.\n",
      "----------------------\n",
      "việt_nam/N là/V nơi/N tôi/N sinh/V ra/V và/C lớn/V lên/V.\n",
      "việt_nam/N là/V nơi/N tôi/N sinh/V ra/V và/C lớn/V lên/V.\n",
      "----------------------\n",
      "khi/N bạn/N nuôi/V một/M con/N vật/N, là/V bạn/N phải/V sẵn_sàng/A chấp_nhận/V nổi_đau/N khi/N mất/V đi/V chúng/P.\n",
      "khi/N bạn/N nuôi/V một/M con/N vật/N, là/V bạn/N phải/V sẵn_sàng/A chấp_nhận/V nổi_đau/N khi/N mất/V đi/V chúng/P.\n",
      "----------------------\n",
      "tôi/N thích/V vẽ/V và/C chơi/V bóng_đá/N.\n",
      "tôi/N thích/V vẽ/V và/C chơi/V bóng_đá/N.\n",
      "----------------------\n",
      "đây/P là/N một/M câu/N nói/V bình_thường/A.\n",
      "đây/P là/V một/M câu/N nói/V bình_thường/A.\n",
      "----------------------\n",
      "tôi/N thích/V những/D điều/N đơn_giản/A.\n",
      "tôi/N thích/V những/D điều/N đơn_giản/A.\n",
      "----------------------\n",
      "những/D người/N nói/V nhiều/A là/V những/D người/N không/R nói/V ít/A.\n",
      "những/D người/N nói/V nhiều/A là/V những/D người/N không/R nói/V ít/A.\n",
      "----------------------\n",
      "họ/P cười/V tôi/N vì/C tôi/N không/R giống/A họ/P.\n",
      "họ/P cười/V tôi/N vì/C tôi/N không/R giống/A họ/P.\n",
      "----------------------\n",
      "tôi/N cười/V họ/P vì/C tôi/N bị/V ngu/A.\n",
      "tôi/N cười/V họ/P vì/C tôi/N bị/V ngu/A.\n",
      "----------------------\n",
      "tôi/N đang/R viết/V những/D dòng/N ngu_ngốc/A.\n",
      "tôi/N đang/R viết/V những/D dòng/N ngu_ngốc/A.\n",
      "----------------------\n",
      "chính/I họ/P là/V thủ_phạm/N.\n",
      "chính/I họ/P là/V thủ_phạm/N.\n",
      "----------------------\n",
      "tôi/N chỉ/R ăn/V trái/N dưa_hấu/N đó/P.\n",
      "tôi/N chỉ/R ăn/V trái/N dưa_hấu/N đó/P.\n",
      "----------------------\n",
      "anh/N ấy/P thường_xuyên/A tắm/V rất/R lâu/A.\n",
      "anh/N ấy/P thường_xuyên/R tắm/V rất/R lâu/A.\n",
      "----------------------\n",
      "em/N cám_ơn/V ạ/I.\n",
      "em/N cám_ơn/V ạ/I.\n",
      "----------------------\n",
      "à/O.\n",
      "à/O.\n",
      "----------------------\n",
      "thôi/O.\n",
      "thôi/O.\n",
      "----------------------\n",
      "anh/N không/R làm/V việc/N đó/P đâu/I.\n",
      "anh/N không/R làm/V việc/N đó/P đâu/I.\n",
      "----------------------\n",
      "tết_nguyên_đán/N không/R chỉ/R là/V khoảng/N thời_gian/N chuyển_giao/V giữa/Q năm/N cũ/A và/C năm/N mới/A âm_lịch/N, mà/C nó/P còn/R chứa_đựng/V nhiều/A ý_nghĩa/N tâm_linh/N, văn_hóa/N,...\n",
      "tết_nguyên_đán/N không/R chỉ/R là/V khoảng/N thời_gian/N chuyển_giao/V giữa/E năm/N cũ/A và/C năm/N mới/A âm_lịch/N, mà/C nó/P còn/R chứa_đựng/V nhiều/A ý_nghĩa/N tâm_linh/N, văn_hóa/N,...\n",
      "----------------------\n",
      "theo/V quan_niệm/N phương/N đông/N, đây/P là/V khoảng/N thời_gian/N trời_đất/N có/V sự/N giao_hòa/V và/C con_người/N trở_nên/V gần/A với/C thần_linh/N.\n",
      "theo/V quan_niệm/N phương/N đông/N, đây/P là/V khoảng/N thời_gian/N trời_đất/N có/V sự/N giao_hòa/V và/C con_người/N trở_nên/V gần/A với/C thần_linh/N.\n",
      "----------------------\n",
      "tết_nguyên_đán/N của/E việt_nam/N được/R tính/V theo/V âm_lịch/N, muộn/V hơn/A tết_dương_lịch/N.\n",
      "tết_nguyên_đán/N của/E việt_nam/N được/R tính/V theo/V âm_lịch/N, muộn/V hơn/A tết_dương_lịch/N.\n",
      "----------------------\n",
      "do/C quy_luật/N ba/M năm/N nhuận/A một/M tháng/N của/E âm_lịch/N nên/C ngày/N đầu/N năm/N của/E dịp/N tết_nguyên_đán/N không/R bao_giờ/P trước/N ngày/N hai_mười_mốt/M tháng/N một/M dương_lịch/N\n",
      "do/C quy_luật/N ba/M năm/N nhuận/A một/M tháng/N của/E âm_lịch/N nên/C ngày/N đầu/N năm/N của/E dịp/N tết_nguyên_đán/N không/R bao_giờ/P trước/N ngày/N hai_mười_mốt/M tháng/N một/M dương_lịch/N\n",
      "----------------------\n",
      "và/C sau/N ngày/N mười_chín/M tháng/N hai/M dương_lịch/N, mà/C thường/R chỉ/R rơi/V vào/E khoảng/N giữa/E những/D ngày/N này/P.\n",
      "và/C sau/N ngày/N mười_chín/M tháng/N hai/M dương_lịch/N, mà/C thường/R chỉ/R rơi/V vào/E khoảng/N giữa/E những/D ngày/N này/P.\n",
      "----------------------\n",
      "thời_gian/N diễn_ra/V tết_nguyên_đán/N hằng/R năm/N thường/R kéo_dài/V trong/C khoảng/N bảy/M -/. tám/M ngày/N cuối/N năm/N cũ/A và/C bảy/M ngày/N đầu/N năm/N mới/A.\n",
      "thời_gian/N diễn_ra/V tết_nguyên_đán/N hằng/R năm/N thường/R kéo_dài/V trong/C khoảng/N bảy/M -/. tám/M ngày/N cuối/N năm/N cũ/A và/C bảy/M ngày/N đầu/N năm/N mới/A.\n",
      "----------------------\n",
      "tết_nguyên_đán/N là/V dịp/N để/C người/N nông_dân/N bày_tỏ/V lòng/N thành_kính/A đến/E các/D vị/N thần_linh/N và/C cầu/V cho/E một/M năm/N mưa/N thuận/A gió/N hòa/A, mùa_màng/N bội_thu/A.\n",
      "tết_nguyên_đán/N là/V dịp/N để/C người/N nông_dân/N bày_tỏ/V lòng/N thành_kính/A đến/E các/D vị/N thần_linh/N và/C cầu/V cho/E một/M năm/N mưa/N thuận/A gió/N hòa/A, mùa_màng/N bội_thu/A.\n",
      "----------------------\n",
      "bên/N cạnh/N đó/P, đây/P còn/R được/R coi/V là/V ngày/N làm/V mới/A, ngày/N để/C mọi/D người/N có_thể/R hy_vọng/V vào/E một/M năm/N mới/A an_lành/A, sung_túc/A, thuận_lợi/A trong/E cả/P năm/N và/C gác_lại/V mọi/D điều/N không/R may_mắn/A trong/E năm/N cũ/A.\n",
      "bên/N cạnh/N đó/P, đây/P còn/R được/R coi/V là/V ngày/N làm/V mới/A, ngày/N để/C mọi/D người/N có_thể/R hy_vọng/V vào/E một/M năm/N mới/A an_lành/A, sung_túc/A, thuận_lợi/A trong/E cả/P năm/N và/C gác_lại/V mọi/D điều/N không/R may_mắn/A trong/C năm/N cũ/A.\n",
      "----------------------\n",
      "do_vậy/C, vào/V dịp/N tết/N, nhà/N nào/P cũng/R tất_bật/A dọn_dẹp/V, sắm_sửa/V, trang_hoàng/V nhà_cửa/N cho/E thật/R đẹp/A.\n",
      "do_vậy/O, vào/V dịp/N tết/N, nhà/N nào/P cũng/R tất_bật/A dọn_dẹp/V, sắm_sửa/V, trang_hoàng/V nhà_cửa/N cho/E thật/R đẹp/A.\n",
      "----------------------\n",
      "đây/E cũng/R là/V dịp/N mọi/D người/N làm/V mới/A lại/R về/E phần/N tình_cảm/N và/C tinh_thần/N để/C mối/N liên_hệ/V với/C người_thân/N được/R gắn_bó/V hơn/A, tinh_thần/N thoải_mái/A, tươi_vui/A hơn/A.\n",
      "đây/P cũng/R là/V dịp/N mọi/D người/N làm/V mới/A lại/R về/E phần/N tình_cảm/N và/C tinh_thần/N để/C mối/N liên_hệ/V với/C người_thân/N được/R gắn_bó/V hơn/A, tinh_thần/N thoải_mái/A, tươi_vui/A hơn/A.\n",
      "----------------------\n",
      "trong/E dịp/N tết/N, các/D gia_đình/N thường/R tụ_họp/V chúc/V tết/N nhau/N, cùng/C nhau/N thắp/V nén/N hương/N tưởng_nhớ/V ông_bà/N, tổ_tiên/N, tạ_ơn/V ông_bà/N, tổ_tiên/N đã/R phù_hộ/V trong/E suốt/A một/M năm/N qua/V.\n",
      "trong/C dịp/N tết/N, các/D gia_đình/N thường/R tụ_họp/V chúc/V tết/N nhau/N, cùng/C nhau/N thắp/V nén/N hương/N tưởng_nhớ/V ông_bà/N, tổ_tiên/N, tạ_ơn/V ông_bà/N, tổ_tiên/N đã/R phù_hộ/V trong/E suốt/A một/M năm/N qua/V.\n",
      "----------------------\n",
      "theo/V quan_niệm/N của/E người/N việt_nam/N, ngày/N tết/N đầu/N xuân/N là/V ngày/N đoàn_tụ/V, đoàn_viên/V, mối/N quan_hệ/N họ_hàng/N làng_xóm/N được/R mở_rộng/V ra/R, ràng_buộc/V lẫn/R nhau/N thành/V đạo_lý/N chung/A cho/E cả/P xã_hội/N :/.\n",
      "theo/V quan_niệm/N của/E người/N việt_nam/N, ngày/N tết/N đầu/N xuân/N là/V ngày/N đoàn_tụ/V, đoàn_viên/V, mối/N quan_hệ/N họ_hàng/N làng_xóm/N được/R mở_rộng/V ra/V, ràng_buộc/V lẫn/D nhau/N thành/V đạo_lý/N chung/A cho/E cả/P xã_hội/I :/.\n",
      "----------------------\n",
      "tình_cảm/N gia_đình/N, tình_cảm/N thầy_trò/N, bệnh_nhân/N với/C thầy_thuốc/N, ông/N mai/N bà/N mối/N đã/R từng/R tác_thành/V đôi_lứa/N, bè_bạn/N cố_tri/N...\n",
      "tình_cảm/N gia_đình/N, tình_cảm/N thầy_trò/N, bệnh_nhân/N với/C thầy_thuốc/N, ông/N mai/N bà/N mối/N đã/R từng/R tác_thành/V đôi_lứa/N, bè_bạn/N cố_tri/N...\n",
      "----------------------\n",
      "trong/C mỗi/D gia_đình/N việt_nam/N, bàn_thờ/N gia_tiên/N có/V một/M vị_trí/N rất/R quan_trọng/A.\n",
      "trong/E mỗi/D gia_đình/N việt_nam/N, bàn_thờ/N gia_tiên/N có/V một/M vị_trí/N rất/R quan_trọng/A.\n",
      "----------------------\n",
      "bàn_thờ/N gia_tiên/N ngày/N tết/N là/V sự/N thể_hiện/V lòng/N tưởng_nhớ/V, kính_trọng/V của/Q người/N việt/N đối_với/C tổ_tiên/N,\n",
      "bàn_thờ/N gia_tiên/N ngày/N tết/N là/V sự/N thể_hiện/V lòng/N tưởng_nhớ/V, kính_trọng/V của/E người/N việt/N đối_với/C tổ_tiên/N,\n",
      "----------------------\n",
      "người_thân/N đã/R khuất/V với/C những/D mâm/N ngũ_quả/N được/R lựa_chọn/V kỹ_lưỡng/A ;/. mâm/N cỗ/N với/C nhiều/A món/N ngon/A hay/R những/D món/N ăn/V quen_thuộc/A của/E người/N đã/R mất/V.\n",
      "người_thân/N đã/R khuất/V với/C những/D mâm/N ngũ_quả/N được/R lựa_chọn/V kỹ_lưỡng/A ;/. mâm/N cỗ/N với/C nhiều/D món/N ngon/A hay/E những/D món/N ăn/V quen_thuộc/A của/E người/N đã/R mất/V.\n",
      "----------------------\n",
      "từ/E đây/P cho/E đến/E hết/A tết/N, khói_hương/N trên/E bàn_thờ/N gia_tiên/N quyện/V với/C không_khí/N thiêng_liêng/A của/E sự/N giao_hòa/V vũ_trụ/N làm/V cho/E con_người/N trở_nên/V gắn_bó/V với/C gia_đình/N của/C mình/P hơn/A bao_giờ/P hết/I.\n",
      "từ/E đây/P cho/E đến/E hết/D tết/N, khói_hương/N trên/E bàn_thờ/N gia_tiên/N quyện/V với/C không_khí/N thiêng_liêng/A của/E sự/N giao_hòa/V vũ_trụ/N làm/V cho/E con_người/N trở_nên/V gắn_bó/V với/C gia_đình/N của/E mình/P hơn/A bao_giờ/P hết/I.\n",
      "----------------------\n",
      "sau/N tết_nguyên_đán/N, cuộc_sống/N lại/R bắt_đầu/V một/M chu_trình/N mới/A của/E một/M năm/N.\n",
      "sau/N tết_nguyên_đán/N, cuộc_sống/N lại/R bắt_đầu/V một/M chu_trình/N mới/A của/E một/M năm/N.\n",
      "----------------------\n",
      "mọi/D người/N trở_về/V với/C công_việc/N thường_nhật/A của/E mình/P, mang/V theo/V những/D tình_cảm/N gia_đình/N đầm_ấm/A có/V được/R trong/E những/D ngày/N tết/N để/C hướng/V đến/E những/D niềm/N vui/A trong/C cuộc_sống/N và/C những/D thành_công/N mới/A trong/C tương_lai/N.\n",
      "mọi/D người/N trở_về/V với/C công_việc/N thường_nhật/A của/E mình/P, mang/V theo/V những/D tình_cảm/N gia_đình/N đầm_ấm/A có/V được/R trong/E những/D ngày/N tết/N để/C hướng/V đến/E những/D niềm/N vui/A trong/C cuộc_sống/N và/C những/D thành_công/N mới/A trong/C tương_lai/N.\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7791842475386779"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_on_test_data( tagged_data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare longest matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_2_sen_words( predict , truth):\n",
    "\tpre_words_size = [len(pre.split(\"_\")) for pre in predict if pre not in DAUCAU] \n",
    "\ttru_words_size = [len(tru.split(\"_\")) for tru in truth if tru not in DAUCAU]\n",
    "\n",
    "\tcount = 0\n",
    "\tstart_pre = 0\n",
    "\tindex_pre = 0\n",
    "\twhile start_pre < sum(pre_words_size):\n",
    "\t\tstart_tru = 0\n",
    "\t\tindex_tru = 0\n",
    "\t\twhile start_tru<start_pre:\n",
    "\t\t\tstart_tru+=tru_words_size[index_tru]\n",
    "\t\t\tindex_tru += 1\n",
    "\t\t\n",
    "\t\tif start_tru == start_pre and pre_words_size[index_pre] == tru_words_size[index_tru]:\n",
    "\t\t\tcount += 1\n",
    "\t\t\n",
    "\t\tstart_pre += pre_words_size[index_pre]\n",
    "\t\tindex_pre += 1\n",
    "\n",
    "\treturn count\n",
    "\n",
    "\n",
    "compare_2_sen_words( sen_to_words(\"ông bà khác ông và bà.\"), sen_to_words(\"ông_bà,,, khác ông và bà\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84251968503937"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longest matching\n",
    "test_sen_words = get_only_words_from_tagged_data( test_data )\n",
    "words_count = 0\n",
    "correct = 0\n",
    "for sen_words in test_sen_words:\n",
    "\twords_count += len(sen_words)\n",
    "\n",
    "\tsen = \" \".join(sen_words)\n",
    "\tsen = sen.replace(\"_\", \" \")\n",
    "\n",
    "\tLongest_matching_words = Longest_matching(sen, words_list)\n",
    "\tcorrect += compare_2_sen_words( Longest_matching_words, sen_words)\n",
    "\n",
    "correct / words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hôm_nay', 'gia_đình', 'hạnh_phúc', '.']\n",
      "['anh', 'chỉ', 'thích', 'em', 'thôi', '.']\n",
      "['tôi', 'đang', 'chơi', 'bóng_đá', '.']\n",
      "['tôi', 'yêu', 'hoa_hồng', '.']\n",
      "['tôi', 'thường_xuyên', 'ăn', 'dưa_hấu', '.']\n",
      "['học_tập', 'để', 'bản_thân', 'không', 'thua_thiệt', 'với', 'bạn_bè', '.']\n",
      "['tôi', 'ghét', 'chơi', 'bóng', '.']\n",
      "['ai', 'cũng', 'tắm', '.']\n",
      "['tết', 'nguyên_đán', 'là', 'ngày', 'đoàn_tụ', 'gia_đình', '.']\n",
      "['đây', 'là', 'khoảng', 'thời_gian', 'thiêng_liêng', 'của', 'người', 'việt', 'nam', '.']\n",
      "['mọi', 'người', 'trong', 'gia_đình', 'chúc', 'tết', 'ông_bà', '.']\n",
      "['ngày', 'để', 'tưởng_nhớ', 'những', 'người_thân', 'đã', 'mất', '.']\n",
      "['thầy_thuốc', 'không', 'bao_giờ', 'lựa_chọn', 'món', 'ăn', 'ngon', '.']\n",
      "['trong', 'dịp', 'tết', 'dương_lịch', ',', 'người', 'việt', 'sắm_sửa', 'hai_mươi', 'mốt', 'mâm', 'ngũ_quả', '.']\n",
      "['gia_đình', 'rất', 'quan_trọng', 'đối_với', 'mỗi', 'con_người', '.']\n",
      "['ngày', 'gia_đình', 'dọn_dẹp', 'là', 'ngày', 'mười', 'chín', 'tháng', 'một', 'hằng', 'năm', '.']\n",
      "['nén', 'hương', 'bắt_đầu', 'quyện', 'vào', 'không_khí', 'thiêng_liêng', 'ngày', 'tết', '.']\n",
      "['tết', 'nguyên_đán', 'là', 'dịp', 'ý_nghĩa', 'để', 'tưởng_nhớ', 'tổ_tiên', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8031496062992126"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# underthesea\n",
    "from underthesea import word_tokenize\n",
    "# Longest matching\n",
    "test_sen_words = get_only_words_from_tagged_data( test_data )\n",
    "words_count = 0\n",
    "correct = 0\n",
    "for sen_words in test_sen_words:\n",
    "\twords_count += len(sen_words)\n",
    "\n",
    "\tsen = \" \".join(sen_words)\n",
    "\tsen = sen.replace(\"_\", \" \")\n",
    "\n",
    "\tunderthesea_words = word_tokenize( sen )\n",
    "\tfor i in range( len(underthesea_words )):\n",
    "\t\tunderthesea_words[i] = underthesea_words[i].replace(\" \",\"_\")\n",
    "\tprint(underthesea_words)\n",
    "\tcorrect += compare_2_sen_words( underthesea_words, sen_words)\n",
    "\n",
    "correct / words_count\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d18648bfca7730471fb15e1319557d0aa883346285fa8720fad782c08b20638"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
